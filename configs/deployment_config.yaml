# configs/deployment_config.yaml
# Configuration for deployment API

# Server settings
server:
  host: "0.0.0.0"
  port: 8000
  debug: false
  workers: 1

# API settings
api:
  title: "Deepfake Detection API"
  description: "API for detecting deepfakes in images and videos"
  version: "1.0.0"
  cors_origins: ["*"]  # CORS origins (* for all, or specific domains)

# Model settings
use_ensemble: true  # Whether to use ensemble model
device: "cuda"  # "cuda" or "cpu"
face_detector: true  # Whether to use face detection

# Single model settings (used if use_ensemble is false)
model:
  type: "vit"  # Options: vit, deit, swin
  checkpoint: "/path/to/checkpoints/vit_best.pth"
  params:
    img_size: 224
    patch_size: 16
    in_channels: 3
    num_classes: 1
    embed_dim: 768
    depth: 12
    num_heads: 12
    mlp_ratio: 4.0
    dropout: 0.1
    attn_dropout: 0.0

# Ensemble settings (used if use_ensemble is true)
ensemble:
  method: "weighted"  # Options: average, voting, weighted, max
  weights: [0.4, 0.3, 0.3]  # Weights for each model (only used with weighted method)
  models:
    - type: "vit"
      checkpoint: "/path/to/checkpoints/vit_best.pth"
      params:
        img_size: 224
        patch_size: 16
        in_channels: 3
        num_classes: 1
        embed_dim: 768
        depth: 12
        num_heads: 12
        mlp_ratio: 4.0
        dropout: 0.1
        attn_dropout: 0.0
    
    - type: "deit"
      checkpoint: "/path/to/checkpoints/deit_best.pth"
      params:
        img_size: 224
        patch_size: 16
        in_channels: 3
        num_classes: 1
        embed_dim: 768
        depth: 12
        num_heads: 12
        mlp_ratio: 4.0
        dropout: 0.1
        attn_dropout: 0.0
        distillation: true
    
    - type: "swin"
      checkpoint: "/path/to/checkpoints/swin_best.pth"
      params:
        img_size: 224
        patch_size: 4
        in_channels: 3
        num_classes: 1
        embed_dim: 96
        depths: [2, 2, 6, 2]
        num_heads: [3, 6, 12, 24]
        window_size: 7
        mlp_ratio: 4.0
        dropout: 0.1
        attn_dropout: 0.0

# Preprocessing settings
preprocessing:
  face_detection:
    method: "mtcnn"  # Options: mtcnn, retinaface
    min_face_size: 40
    margin: 0.2
  
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    size: 224

# Video processing settings
video:
  sample_rate: 30  # Process one frame every N frames
  batch_size: 16  # Batch size for frame processing
  max_frames: null  # Maximum number of frames to process (null for all frames)
  temporal_window: 5  # Window size for temporal smoothing
  create_analysis_video: true  # Whether to create analysis visualization video

# Output settings
output_dir: "output"  # Directory to save results
max_results: 100  # Maximum number of results to keep

# Explanation settings
explanation:
  enabled: true  # Whether to generate explanations by default
  grad_cam: true  # Whether to visualize Grad-CAM
  attention_maps: true  # Whether to visualize attention maps

# Caching settings
cache:
  enabled: true  # Whether to enable caching
  expiration: 3600  # Cache expiration time in seconds (1 hour)