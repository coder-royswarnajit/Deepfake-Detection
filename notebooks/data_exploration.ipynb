{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afca33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Deepfake Detection Dataset Exploration\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook explores the datasets used for deepfake detection training and evaluation. It provides statistics, visualizations, and insights into the data distributions and characteristics.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Datasets:\\n\",\n",
    "    \"- FaceForensics++ - A diverse dataset with various deepfake methods\\n\",\n",
    "    \"- Celeb-DF - High-quality celebrity deepfake videos\\n\",\n",
    "    \"- Combined datasets for more robust training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from torch.utils.data import DataLoader\\n\",\n",
    "    \"import torchvision.transforms as transforms\\n\",\n",
    "    \"from tqdm.notebook import tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add parent directory to path to enable imports from project\\n\",\n",
    "    \"sys.path.append(os.path.abspath('..'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import project modules\\n\",\n",
    "    \"from data.datasets.faceforensics import FaceForensicsDataset\\n\",\n",
    "    \"from data.datasets.celebdf import CelebDFDataset\\n\",\n",
    "    \"from data.datasets.custom_dataset import DeepfakeDataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set plot style\\n\",\n",
    "    \"plt.style.use('fivethirtyeight')\\n\",\n",
    "    \"sns.set(style=\\\"whitegrid\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Configure Dataset Paths\\n\",\n",
    "    \"\\n\",\n",
    "    \"Set the paths to the datasets on your system.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Configure dataset paths - update these to your local paths\\n\",\n",
    "    \"FACEFORENSICS_ROOT = \\\"/path/to/datasets/FaceForensics\\\"\\n\",\n",
    "    \"CELEBDF_ROOT = \\\"/path/to/datasets/CelebDF\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if directories exist\\n\",\n",
    "    \"ff_exists = os.path.exists(FACEFORENSICS_ROOT)\\n\",\n",
    "    \"celebdf_exists = os.path.exists(CELEBDF_ROOT)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"FaceForensics++ path exists: {ff_exists}\\\")\\n\",\n",
    "    \"print(f\\\"Celeb-DF path exists: {celebdf_exists}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load Datasets\\n\",\n",
    "    \"\\n\",\n",
    "    \"Load each dataset and examine its structure.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Only execute if datasets exist\\n\",\n",
    "    \"# Create transform for visualization\\n\",\n",
    "    \"vis_transform = transforms.Compose([\\n\",\n",
    "    \"    transforms.Resize((224, 224)),\\n\",\n",
    "    \"    transforms.ToTensor()\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"datasets = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load FaceForensics++ dataset if available\\n\",\n",
    "    \"if ff_exists:\\n\",\n",
    "    \"    print(\\\"Loading FaceForensics++ dataset...\\\")\\n\",\n",
    "    \"    methods = [\\\"Deepfakes\\\", \\\"Face2Face\\\", \\\"FaceSwap\\\", \\\"NeuralTextures\\\"]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ff_dataset = FaceForensicsDataset(\\n\",\n",
    "    \"        root=FACEFORENSICS_ROOT,\\n\",\n",
    "    \"        split=\\\"train\\\",  # Use train split for exploration\\n\",\n",
    "    \"        img_size=224,\\n\",\n",
    "    \"        transform=vis_transform,\\n\",\n",
    "    \"        methods=methods\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    datasets[\\\"faceforensics\\\"] = ff_dataset\\n\",\n",
    "    \"    print(f\\\"FaceForensics++ dataset loaded with {len(ff_dataset)} samples\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"FaceForensics++ dataset path not found. Skipping...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load Celeb-DF dataset if available\\n\",\n",
    "    \"if celebdf_exists:\\n\",\n",
    "    \"    print(\\\"Loading Celeb-DF dataset...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    celebdf_dataset = CelebDFDataset(\\n\",\n",
    "    \"        root=CELEBDF_ROOT,\\n\",\n",
    "    \"        split=\\\"train\\\",  # Use train split for exploration\\n\",\n",
    "    \"        img_size=224,\\n\",\n",
    "    \"        transform=vis_transform\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    datasets[\\\"celebdf\\\"] = celebdf_dataset\\n\",\n",
    "    \"    print(f\\\"Celeb-DF dataset loaded with {len(celebdf_dataset)} samples\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Celeb-DF dataset path not found. Skipping...\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Analyze Class Distribution\\n\",\n",
    "    \"\\n\",\n",
    "    \"Check the balance between real and fake samples in each dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def analyze_class_distribution(dataset, name):\\n\",\n",
    "    \"    \\\"\\\"\\\"Analyze and visualize class distribution in a dataset\\\"\\\"\\\"\\n\",\n",
    "    \"    # Count real (0) and fake (1) samples\\n\",\n",
    "    \"    real_count = 0\\n\",\n",
    "    \"    fake_count = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for _, label in tqdm(dataset, desc=f\\\"Analyzing {name}\\\"):\\n\",\n",
    "    \"        if label == 0:\\n\",\n",
    "    \"            real_count += 1\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            fake_count += 1\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    total = real_count + fake_count\\n\",\n",
    "    \"    real_percent = (real_count / total) * 100\\n\",\n",
    "    \"    fake_percent = (fake_count / total) * 100\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{name} Dataset Distribution:\\\")\\n\",\n",
    "    \"    print(f\\\"Total samples: {total}\\\")\\n\",\n",
    "    \"    print(f\\\"Real samples: {real_count} ({real_percent:.2f}%)\\\")\\n\",\n",
    "    \"    print(f\\\"Fake samples: {fake_count} ({fake_percent:.2f}%)\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Visualize distribution\\n\",\n",
    "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"    sns.barplot(x=['Real', 'Fake'], y=[real_count, fake_count])\\n\",\n",
    "    \"    plt.title(f\\\"{name} Dataset Class Distribution\\\")\\n\",\n",
    "    \"    plt.ylabel('Count')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {'real': real_count, 'fake': fake_count, 'total': total}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Analyze each dataset\\n\",\n",
    "    \"distributions = {}\\n\",\n",
    "    \"for name, dataset in datasets.items():\\n\",\n",
    "    \"    distributions[name] = analyze_class_distribution(dataset, name)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Visualize Sample Images\\n\",\n",
    "    \"\\n\",\n",
    "    \"Display sample images from each dataset to better understand the data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def visualize_samples(dataset, name, num_samples=5):\\n\",\n",
    "    \"    \\\"\\\"\\\"Visualize random samples from the dataset\\\"\\\"\\\"\\n\",\n",
    "    \"    # Create dataloaders\\n\",\n",
    "    \"    dataloader = DataLoader(dataset, batch_size=num_samples*2, shuffle=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get a batch\\n\",\n",
    "    \"    images, labels = next(iter(dataloader))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Separate real and fake samples\\n\",\n",
    "    \"    real_images = [img for img, label in zip(images, labels) if label == 0]\\n\",\n",
    "    \"    fake_images = [img for img, label in zip(images, labels) if label == 1]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Keep only num_samples of each\\n\",\n",
    "    \"    real_images = real_images[:num_samples]\\n\",\n",
    "    \"    fake_images = fake_images[:num_samples]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\\n\",\n",
    "    \"    fig.suptitle(f\\\"{name} Dataset Samples\\\", fontsize=16)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot real samples (top row)\\n\",\n",
    "    \"    for i, img in enumerate(real_images):\\n\",\n",
    "    \"        img = img.permute(1, 2, 0).numpy()  # CHW -> HWC\\n\",\n",
    "    \"        axes[0, i].imshow(img)\\n\",\n",
    "    \"        axes[0, i].set_title(\\\"Real\\\")\\n\",\n",
    "    \"        axes[0, i].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot fake samples (bottom row)\\n\",\n",
    "    \"    for i, img in enumerate(fake_images):\\n\",\n",
    "    \"        img = img.permute(1, 2, 0).numpy()  # CHW -> HWC\\n\",\n",
    "    \"        axes[1, i].imshow(img)\\n\",\n",
    "    \"        axes[1, i].set_title(\\\"Fake\\\")\\n\",\n",
    "    \"        axes[1, i].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout(rect=[0, 0, 1, 0.95])\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize samples from each dataset\\n\",\n",
    "    \"for name, dataset in datasets.items():\\n\",\n",
    "    \"    visualize_samples(dataset, name, num_samples=5)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Analyze Image Quality and Properties\\n\",\n",
    "    \"\\n\",\n",
    "    \"Analyze image properties like brightness, contrast, and quality.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def calculate_image_metrics(image_tensor):\\n\",\n",
    "    \"    \\\"\\\"\\\"Calculate image metrics: brightness, contrast, blur\\\"\\\"\\\"\\n\",\n",
    "    \"    # Convert tensor to numpy\\n\",\n",
    "    \"    img = image_tensor.permute(1, 2, 0).numpy()\\n\",\n",
    "    \"    img = (img * 255).astype(np.uint8)  # Scale to 0-255\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Convert to grayscale for some metrics\\n\",\n",
    "    \"    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate brightness (mean pixel value)\\n\",\n",
    "    \"    brightness = np.mean(gray)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate contrast (standard deviation)\\n\",\n",
    "    \"    contrast = np.std(gray)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate blur level (variance of Laplacian)\\n\",\n",
    "    \"    blur = cv2.Laplacian(gray, cv2.CV_64F).var()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        'brightness': brightness,\\n\",\n",
    "    \"        'contrast': contrast,\\n\",\n",
    "    \"        'blur': blur\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"def analyze_image_properties(dataset, name, num_samples=100):\\n\",\n",
    "    \"    \\\"\\\"\\\"Analyze image properties for a subset of the dataset\\\"\\\"\\\"\\n\",\n",
    "    \"    # Create DataLoader\\n\",\n",
    "    \"    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Initialize lists for metrics\\n\",\n",
    "    \"    metrics_real = []\\n\",\n",
    "    \"    metrics_fake = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Analyze samples\\n\",\n",
    "    \"    real_count = 0\\n\",\n",
    "    \"    fake_count = 0\\n\",\n",
    "    \"    target_count = num_samples // 2  # Target for each class\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for img, label in tqdm(dataloader, desc=f\\\"Analyzing {name} properties\\\"):\\n\",\n",
    "    \"        # Calculate metrics\\n\",\n",
    "    \"        metrics = calculate_image_metrics(img[0])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add to appropriate list\\n\",\n",
    "    \"        if label.item() == 0 and real_count < target_count:\\n\",\n",
    "    \"            metrics_real.append(metrics)\\n\",\n",
    "    \"            real_count += 1\\n\",\n",
    "    \"        elif label.item() == 1 and fake_count < target_count:\\n\",\n",
    "    \"            metrics_fake.append(metrics)\\n\",\n",
    "    \"            fake_count += 1\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Check if we have enough samples\\n\",\n",
    "    \"        if real_count >= target_count and fake_count >= target_count:\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Convert to DataFrames\\n\",\n",
    "    \"    df_real = pd.DataFrame(metrics_real)\\n\",\n",
    "    \"    df_real['class'] = 'Real'\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df_fake = pd.DataFrame(metrics_fake)\\n\",\n",
    "    \"    df_fake['class'] = 'Fake'\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Combine\\n\",\n",
    "    \"    df = pd.concat([df_real, df_fake])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot distributions\\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\\n\",\n",
    "    \"    fig.suptitle(f\\\"{name} Dataset Image Properties\\\", fontsize=16)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Brightness\\n\",\n",
    "    \"    sns.boxplot(x='class', y='brightness', data=df, ax=axes[0])\\n\",\n",
    "    \"    axes[0].set_title('Brightness Distribution')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Contrast\\n\",\n",
    "    \"    sns.boxplot(x='class', y='contrast', data=df, ax=axes[1])\\n\",\n",
    "    \"    axes[1].set_title('Contrast Distribution')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Blur\\n\",\n",
    "    \"    sns.boxplot(x='class', y='blur', data=df, ax=axes[2])\\n\",\n",
    "    \"    axes[2].set_title('Blur Level Distribution')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout(rect=[0, 0, 1, 0.95])\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Analyze image properties for each dataset\\n\",\n",
    "    \"image_properties = {}\\n\",\n",
    "    \"for name, dataset in datasets.items():\\n\",\n",
    "    \"    image_properties[name] = analyze_image_properties(dataset, name, num_samples=100)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Face Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Analyze facial features in the datasets.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def analyze_faces(dataset, name, num_samples=20):\\n\",\n",
    "    \"    \\\"\\\"\\\"Analyze facial features using a face detection library\\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        import dlib\\n\",\n",
    "    \"        print(\\\"Using dlib for face analysis...\\\")\\n\",\n",
    "    \"    except ImportError:\\n\",\n",
    "    \"        print(\\\"dlib not installed. Please install dlib for face analysis:\\\")\\n\",\n",
    "    \"        print(\\\"pip install dlib\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load face detector and landmark predictor\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        detector = dlib.get_frontal_face_detector()\\n\",\n",
    "    \"        predictor_path = \\\"shape_predictor_68_face_landmarks.dat\\\"  # You need to download this file\\n\",\n",
    "    \"        if os.path.exists(predictor_path):\\n\",\n",
    "    \"            predictor = dlib.shape_predictor(predictor_path)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"Landmark predictor model not found at {predictor_path}\\\")\\n\",\n",
    "    \"            print(\\\"Please download it from: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\\\")\\n\",\n",
    "    \"            return\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error loading dlib models: {e}\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create dataloader\\n\",\n",
    "    \"    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Function to draw landmarks\\n\",\n",
    "    \"    def draw_landmarks(img, landmarks):\\n\",\n",
    "    \"        img_copy = img.copy()\\n\",\n",
    "    \"        for i in range(68):\\n\",\n",
    "    \"            x, y = landmarks.part(i).x, landmarks.part(i).y\\n\",\n",
    "    \"            cv2.circle(img_copy, (x, y), 2, (0, 255, 0), -1)\\n\",\n",
    "    \"        return img_copy\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Analyze samples\\n\",\n",
    "    \"    real_samples = []\\n\",\n",
    "    \"    fake_samples = []\\n\",\n",
    "    \"    real_count = 0\\n\",\n",
    "    \"    fake_count = 0\\n\",\n",
    "    \"    target_count = num_samples // 2\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for img, label in tqdm(dataloader, desc=f\\\"Analyzing {name} faces\\\"):\\n\",\n",
    "    \"        img_np = img[0].permute(1, 2, 0).numpy() \\n\",\n",
    "    \"        img_np = (img_np * 255).astype(np.uint8)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Detect faces\\n\",\n",
    "    \"        faces = detector(img_np)\\n\",\n",
    "    \"        if len(faces) == 0:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        face = faces[0]  # Use first face\\n\",\n",
    "    \"        landmarks = predictor(img_np, face)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Draw landmarks\\n\",\n",
    "    \"        img_landmarks = draw_landmarks(img_np, landmarks)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add to appropriate list\\n\",\n",
    "    \"        if label.item() == 0 and real_count < target_count:\\n\",\n",
    "    \"            real_samples.append((img_np, img_landmarks))\\n\",\n",
    "    \"            real_count += 1\\n\",\n",
    "    \"        elif label.item() == 1 and fake_count < target_count:\\n\",\n",
    "    \"            fake_samples.append((img_np, img_landmarks))\\n\",\n",
    "    \"            fake_count += 1\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Check if we have enough samples\\n\",\n",
    "    \"        if real_count >= target_count and fake_count >= target_count:\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Visualize results\\n\",\n",
    "    \"    if real_samples and fake_samples:\\n\",\n",
    "    \"        rows = min(len(real_samples), len(fake_samples))\\n\",\n",
    "    \"        fig, axes = plt.subplots(rows, 4, figsize=(15, rows*3))\\n\",\n",
    "    \"        fig.suptitle(f\\\"{name} Dataset Face Analysis\\\", fontsize=16)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        for i in range(rows):\\n\",\n",
    "    \"            # Real samples\\n\",\n",
    "    \"            axes[i, 0].imshow(real_samples[i][0])\\n\",\n",
    "    \"            axes[i, 0].set_title(\\\"Real\\\")\\n\",\n",
    "    \"            axes[i, 0].axis('off')\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            axes[i, 1].imshow(real_samples[i][1])\\n\",\n",
    "    \"            axes[i, 1].set_title(\\\"Real (Landmarks)\\\")\\n\",\n",
    "    \"            axes[i, 1].axis('off')\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Fake samples\\n\",\n",
    "    \"            axes[i, 2].imshow(fake_samples[i][0])\\n\",\n",
    "    \"            axes[i, 2].set_title(\\\"Fake\\\")\\n\",\n",
    "    \"            axes[i, 2].axis('off')\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            axes[i, 3].imshow(fake_samples[i][1])\\n\",\n",
    "    \"            axes[i, 3].set_title(\\\"Fake (Landmarks)\\\")\\n\",\n",
    "    \"            axes[i, 3].axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout(rect=[0, 0, 1, 0.95])\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Try analyzing faces if dlib is installed\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import dlib\\n\",\n",
    "    \"    for name, dataset in datasets.items():\\n\",\n",
    "    \"        analyze_faces(dataset, name, num_samples=10)\\n\",\n",
    "    \"except ImportError:\\n\",\n",
    "    \"    print(\\\"dlib not installed. Skipping face analysis.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Cross-Dataset Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Compare properties across different datasets to understand their similarities and differences.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Skip if we don't have multiple datasets to compare\\n\",\n",
    "    \"if len(datasets) > 1 and len(image_properties) > 1:\\n\",\n",
    "    \"    # Prepare data for comparison\\n\",\n",
    "    \"    comparison_data = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for name, df in image_properties.items():\\n\",\n",
    "    \"        df_copy = df.copy()\\n\",\n",
    "    \"        df_copy['dataset'] = name\\n\",\n",
    "    \"        comparison_data.append(df_copy)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Combine data\\n\",\n",
    "    \"    combined_df = pd.concat(comparison_data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create comparison plots\\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\\n\",\n",
    "    \"    fig.suptitle(\\\"Cross-Dataset Comparison\\\", fontsize=16)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Brightness comparison\\n\",\n",
    "    \"    sns.boxplot(x='dataset', y='brightness', hue='class', data=combined_df, ax=axes[0])\\n\",\n",
    "    \"    axes[0].set_title('Brightness Comparison')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Contrast comparison\\n\",\n",
    "    \"    sns.boxplot(x='dataset', y='contrast', hue='class', data=combined_df, ax=axes[1])\\n\",\n",
    "    \"    axes[1].set_title('Contrast Comparison')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Blur comparison\\n\",\n",
    "    \"    sns.boxplot(x='dataset', y='blur', hue='class', data=combined_df, ax=axes[2])\\n\",\n",
    "    \"    axes[2].set_title('Blur Level Comparison')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout(rect=[0, 0, 1, 0.95])\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Need at least 2 datasets for cross-dataset comparison.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Summary and Insights\\n\",\n",
    "    \"\\n\",\n",
    "    \"Summarize key findings and insights about the datasets.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Create summary table\\n\",\n",
    "    \"if distributions:\\n\",\n",
    "    \"    summary_data = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for name, dist in distributions.items():\\n\",\n",
    "    \"        row = {\\n\",\n",
    "    \"            'Dataset': name,\\n\",\n",
    "    \"            'Total Samples': dist['total'],\\n\",\n",
    "    \"            'Real Samples': dist['real'],\\n\",\n",
    "    \"            'Fake Samples': dist['fake'],\\n\",\n",
    "    \"            'Real %': round((dist['real'] / dist['total']) * 100, 2),\\n\",\n",
    "    \"            'Fake %': round((dist['fake'] / dist['total']) * 100, 2)\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        summary_data.append(row)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    summary_df = pd.DataFrame(summary_data)\\n\",\n",
    "    \"    print(\\\"Dataset Summary:\\\")\\n\",\n",
    "    \"    display(summary_df)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add insights\\n\",\n",
    "    \"    print(\\\"\\\\nKey Insights:\\\")\\n\",\n",
    "    \"    for name in distributions.keys():\\n\",\n",
    "    \"        print(f\\\"\\\\n{name.upper()} Dataset:\\\")\\n\",\n",
    "    \"        print(f\\\"- Contains {distributions[name]['total']} total samples\\\")\\n\",\n",
    "    \"        print(f\\\"- Class balance: {distributions[name]['real']} real vs {distributions[name]['fake']} fake samples\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if name in image_properties:\\n\",\n",
    "    \"            df = image_properties[name]\\n\",\n",
    "    \"            real_df = df[df['class'] == 'Real']\\n\",\n",
    "    \"            fake_df = df[df['class'] == 'Fake']\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Brightness comparison\\n\",\n",
    "    \"            real_brightness = real_df['brightness'].mean()\\n\",\n",
    "    \"            fake_brightness = fake_df['brightness'].mean()\\n\",\n",
    "    \"            brightness_diff = abs(real_brightness - fake_brightness)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if brightness_diff > 10:\\n\",\n",
    "    \"                print(f\\\"- Notable brightness difference between real and fake samples: {brightness_diff:.1f}\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"            # Contrast comparison\\n\",\n",
    "    \"            real_contrast = real_df['contrast'].mean()\\n\",\n",
    "    \"            fake_contrast = fake_df['contrast'].mean()\\n\",\n",
    "    \"            contrast_diff = abs(real_contrast - fake_contrast)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if contrast_diff > 5:\\n\",\n",
    "    \"                print(f\\\"- Notable contrast difference between real and fake samples: {contrast_diff:.1f}\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"            # Blur comparison\\n\",\n",
    "    \"            real_blur = real_df['blur'].mean()\\n\",\n",
    "    \"            fake_blur = fake_df['blur'].mean()\\n\",\n",
    "    \"            blur_diff = abs(real_blur - fake_blur)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if blur_diff > 100:\\n\",\n",
    "    \"                print(f\\\"- Notable blur level difference between real and fake samples: {blur_diff:.1f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No dataset distributions available for summary.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Potential Improvements\\n\",\n",
    "    \"\\n\",\n",
    "    \"Based on the analysis, here are some potential improvements for data preparation:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Data Augmentation Suggestions\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Address class imbalance**: If there's a significant imbalance between real and fake samples, consider techniques like:\\n\",\n",
    "    \"   - Oversampling the minority class\\n\",\n",
    "    \"   - Undersampling the majority class\\n\",\n",
    "    \"   - Using weighted loss functions\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Normalize image properties**: If there are significant differences in brightness, contrast, or blur levels between real and fake samples, consider:\\n\",\n",
    "    \"   - Applying consistent normalization\\n\",\n",
    "    \"   - Using augmentations that specifically target these differences\\n\",\n",
    "    \"\\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
